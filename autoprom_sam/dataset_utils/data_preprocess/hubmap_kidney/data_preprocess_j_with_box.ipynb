{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from patchify import patchify\n",
    "import tifffile as tiff\n",
    "import gc\n",
    "from PIL import Image, ImageDraw\n",
    "import pandas as pd\n",
    "BASE_WSI_PATH = '/home/humanoid/datasets/Hubmap-kidney/'\n",
    "# The tile sizes\n",
    "size_x = 2048\n",
    "size_y = 2048\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list(folder):\n",
    "    files_list = os.listdir(BASE_WSI_PATH+folder)\n",
    "    files = []\n",
    "    for file in files_list:\n",
    "        if \".tiff\" in file:\n",
    "            files.append(file.split(\".\")[0])\n",
    "    return files\n",
    "#%%\n",
    "def read_tiff(file_id,folder):\n",
    "    '''\n",
    "        This funciton will take a tiff file id with its folder location and read it. It should note that format of tiff\n",
    "        files are not same across the folder. Some tiff images has more dims than other and sometimes the color channel\n",
    "        is located differently. This need to checked manually before creating this funcion.\n",
    "    '''\n",
    "    print(\"Reading file \",file_id,end=\"\")\n",
    "    large_image_stack = tiff.imread(BASE_WSI_PATH+folder+'/'+file_id+'.tiff')#[0,0,:,:,:]\n",
    "    print(\"Done\")\n",
    "    shape = large_image_stack.shape\n",
    "    if(len(shape)>3):\n",
    "        print(\"Image has more dims\")\n",
    "        large_image_stack = tiff.imread(BASE_WSI_PATH+folder+'/'+file_id+'.tiff')[0,0,:,:,:]\n",
    "    else:\n",
    "        print(\"Image has 3 dims\")\n",
    "    shape = large_image_stack.shape\n",
    "    if shape[0]==3:\n",
    "        print(\"Image is channel first, converting\")\n",
    "        large_image_stack = np.einsum('ijk->jki',large_image_stack)\n",
    "    else:\n",
    "        print(\"Image is channel last, no need to convert\")\n",
    "    shape = large_image_stack.shape\n",
    "    print(shape)\n",
    "    return large_image_stack, shape\n",
    "# %%\n",
    "import json\n",
    "def read_mask(file_id,dir = \"train\"):    \n",
    "    '''\n",
    "        This function will take the id of the tiff image and serach for its mask in the training file\n",
    "        folder. It first opens the json file, use geometry & coordinates fields to make polygons, draw\n",
    "        the image using the polygons and returns it as the mask\n",
    "    '''\n",
    "    json_filename = BASE_WSI_PATH+f\"train/\"+file_id+'.json'\n",
    "    read_file = open(json_filename, \"r\") \n",
    "    data = json.load(read_file)\n",
    "\n",
    "    polys = []\n",
    "    for index in range(data.__len__()):\n",
    "        geom = np.array(data[index]['geometry']['coordinates'])\n",
    "        polys.append(geom)\n",
    "    #shape = (38160, 39000)\n",
    "\n",
    "    Image.MAX_IMAGE_PIXELS = None\n",
    "    mask = Image.new('L', (shape[1], shape[0]), 0)  # (w, h)\n",
    "    for i in range(len(polys)):\n",
    "        poly = polys[i]\n",
    "        ImageDraw.Draw(mask).polygon(tuple(map(tuple, poly[0])), outline=i + 1, fill=i + 1) \n",
    "    polys = []\n",
    "    mask = np.array(mask)\n",
    "    return mask\n",
    "# %%\n",
    "files = file_list('train') # to list all files in the train directory\n",
    "# %%\n",
    "files\n",
    "# %%\n",
    "test_files = file_list('test')\n",
    "test_files\n",
    "# %%\n",
    "# \n",
    "import torch\n",
    "import albumentations as A\n",
    "\n",
    "# We can do many transformations\n",
    "seq = A.Compose([\n",
    "        A.HorizontalFlip(),\n",
    "        A.Rotate(limit=(-45, 45)),\n",
    "        # A.RandomCrop(128, 128),\n",
    "        #A.ToTensor(),\n",
    "    ])\n",
    "seq_ = A.Compose([\n",
    "        A.VerticalFlip(),\n",
    "         A.ShiftScaleRotate(),\n",
    "    ])\n",
    "seq_s = A.Compose([\n",
    "        #A.GaussianBlur(blur_limit=(3, 7),p=0.5),\n",
    "        A.ColorJitter (brightness=0.05, contrast=0.01, saturation=0.01, hue=0.1, always_apply=False, p=0.5)\n",
    "        #A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), always_apply=False, p=1.0)\n",
    "        ])\n",
    "seq_both = [seq,seq_]\n",
    "\n",
    "# %%\n",
    "print(\"rxtracting\")\n",
    "files = file_list('train') # to list all files in the train directory\n",
    "c = 0\n",
    "patch_length = size_x # tile size\n",
    "step = int(size_x*0.25) # tile after every this much of pixels\n",
    "#create pandas dataframe\n",
    "df = pd.DataFrame(columns=[\"Image_path\",\"Mask_path\",\"Image_orig_size\"])\n",
    "resize = 256 # whole image should be resized to this before saving it\n",
    "items = 0\n",
    "for file_id in files[:]:\n",
    "    large_image_stack, shape = read_tiff(file_id,\"train\")\n",
    "    # if needed do the resize as below, but it take lot of resources\n",
    "    #large_image_stack = cv2.resize(large_image_stack,(shape[1]//3,shape[0]//3))\n",
    "    print(\"New shape,\",shape)\n",
    "    # easy tiling of the large image\n",
    "    patches_img = patchify(large_image_stack, (patch_length, patch_length, 3), step=step)\n",
    "    # save memory\n",
    "    large_image_stack = \"\"\n",
    "    gc.collect()\n",
    "    \n",
    "    # do the same for the mask\n",
    "    mask = read_mask(file_id)\n",
    "    patches_mask = patchify(mask, (patch_length, patch_length), step=step)\n",
    "    mask = \"\"\n",
    "    gc.collect()\n",
    "    \n",
    "    # calculate the percentage of the mask in the tiled image\n",
    "    count = 0\n",
    "    sums = []\n",
    "    for row in range(patches_mask.shape[0]):\n",
    "        for col in range(patches_mask.shape[1]):\n",
    "            s = np.sum(patches_mask[row,col,:,:])\n",
    "            count+=1\n",
    "            sums.append([s, row, col, np.round(s/(patch_length*patch_length*255),2)])\n",
    "    sums.sort()\n",
    "    #if wanted filter images based on the coverage of the mask\n",
    "    #ex: first 10% with zero masks + 40-60% mask coverage in the middle + more than 90% mask coverage\n",
    "    #sums = sums[0:int(len(sums)*.10)]+sums[int(len(sums)*.40):int(len(sums)*.60)]+(sums[int(len(sums)*.90):])\n",
    "    print(len(sums))\n",
    "    c = 0\n",
    "    for im in sums:\n",
    "        c+=1\n",
    "        row = im[1]\n",
    "        col = im[2]\n",
    "\n",
    "        # seperate corresponding image and its mask using sums list\n",
    "        image = patches_img[row,col,0,:,:,:]\n",
    "        image = cv2.resize(image, (resize, resize))\n",
    "        mask = patches_mask[row,col,:,:]\n",
    "        mask = cv2.resize(mask, (resize, resize))\n",
    "        mask = (mask>0).astype(int)\n",
    "        #create uniqe file names\n",
    "        filename_image = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_image.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"image.jpg\"\n",
    "        cv2.imwrite(\"/home/humanoid/datasets/Hubmap-kidney/train_patch_image/\"+filename_image, image)\n",
    "        filename_mask = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_mask.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"mask.jpg\"\n",
    "        cv2.imwrite(\"/home/humanoid/datasets/Hubmap-kidney/train_patch_mask/\"+filename_mask, mask*255)\n",
    "        df = df.append({\"Image_path\":filename_image,\"Mask_path\":filename_mask,\"Image_orig_size\":resize},ignore_index=True)\n",
    "        \"\"\"\n",
    "        filename_image = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_image.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"image.jpg\"\n",
    "        cv2.imwrite(\"/home/humanoid/internalHD/datasets/kidney_patch/train/image/\"+filename_image, org_img)\n",
    "        filename_mask = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_mask.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"mask.jpg\"\n",
    "        cv2.imwrite(\"/home/humanoid/internalHD/datasets/kidney_patch/train/masks/\"+filename_mask, org_msk*255)\n",
    "\n",
    "        filename_image = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_image_aug0.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"image.jpg\"\n",
    "        cv2.imwrite(\"/home/humanoid/internalHD/datasets/kidney_patch/train/image/\"+filename_image, aug_img)\n",
    "        filename_mask = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_mask_aug0.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"mask.jpg\"\n",
    "        cv2.imwrite(\"/home/humanoid/internalHD/datasets/kidney_patch/train/masks/\"+filename_mask, aug_mask*255)\n",
    "\n",
    "        filename_image = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_image_aug1.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"image.jpg\"\n",
    "        cv2.imwrite(\"/home/humanoid/internalHD/datasets/kidney_patch/train/image/\"+filename_image, aug_img1)\n",
    "        filename_mask = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_mask_aug1.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"mask.jpg\"\n",
    "        cv2.imwrite(\"/home/humanoid/internalHD/datasets/kidney_patch/train/masks/\"+filename_mask, aug_mask1*255)\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        #use following if some randomness is required in saving images\n",
    "#         num = random.randint(1,100)\n",
    "#         #print(\"Num is {}\".format(num))\n",
    "#         if num>=50:\n",
    "#             filename_image = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_image_aug.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"image.jpg\"\n",
    "#             cv2.imwrite(\"./images/\"+filename_image, aug_img)\n",
    "#             filename_mask = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_mask_aug.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"mask.jpg\"\n",
    "#             cv2.imwrite(\"./masks/\"+filename_mask, org_msk*255)\n",
    "        print(\".\",end=\"\")       \n",
    "            #if im[3]>=.30: break\n",
    "            #print(row, col, filename_image, filename_mask, \"saved\")\n",
    "    df.to_csv(\"train_df.csv\",index=False)\n",
    "    print()\n",
    "    print(items,\" \",\"Done\",c,\" images\")\n",
    "    print()\n",
    "    items+=1\n",
    "    gc.collect()\n",
    "    \n",
    "# print(\"DONE=================\")\n",
    "# # %%\n",
    "# # Inspeck few images ans its masks\n",
    "# patch_path = \"/home/humanoid/internalHD/datasets/kidney_patch/\"\n",
    "# ims = os.listdir(patch_path+'train/image')\n",
    "# #mask = os.listdir(patch_path+'train/masks')\n",
    "# random.shuffle(ims)\n",
    "# msk = [i.replace(\"image\",\"mask\") for i in ims]\n",
    "# ims = [f'{patch_path}train/image/'+x for x in ims]\n",
    "# msk = [f'{patch_path}train/masks/'+x for x in msk]\n",
    "# fig, axs = plt.subplots(1,2,figsize=(10,10))\n",
    "# num = random.randint(1,len(ims))\n",
    "# print(num)\n",
    "# m = cv2.imread(ims[num])\n",
    "# n = cv2.imread(msk[num])\n",
    "# axs[0].imshow(m)\n",
    "# axs[1].imshow(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_ws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
